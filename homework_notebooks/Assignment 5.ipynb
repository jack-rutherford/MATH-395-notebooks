{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b9ef8-44b4-446c-9136-6355c4535fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b504a-5516-43bd-9e4d-b5b40841cf8b",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83714c26-0791-4a3c-943d-bead7bf699ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('../datasets/fashion.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c53af-b750-440c-947a-251c214699ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mat['Xtr']\n",
    "y_train = mat['ytr']\n",
    "X_test = mat['Xtst']\n",
    "y_test = mat['ytst']\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498c1de-df4a-4fbc-b842-2944769fe6e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. nearest centroid classification with original images (no pca yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3b7f7-7a51-4c61-b037-bf1660007ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NearestCentroid()\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('error = ', 1- accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bee2b5-1566-4685-9388-f055f55d44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=clf.classes_)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a2b47-6cc3-45f8-b720-a1aa2f01d821",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Apply PCA to reduce dimension first and then perform k nearest neighbor (kNN) classification (Euclidean distance, no weighting).\n",
    "\n",
    "For this data set, 50 dimensions might no longer be the best choice. So there are two parameters to be tuned: m (number of pca dimensions) and k (number of nearest neighbors).\n",
    "\n",
    "A large scale grid search over (m,k) could find the optimal pair in terms of test error (or validation error). However, it will be slow.\n",
    "\n",
    "Here, let us fix m to a small number of values such as 50, 100, 150 (feel free to change these numbers). For each value of m, perform PCA to project both the training and test data into the same m dimensional space. Afterwards, perform kNN classification on the m-dimensional PCA reduced data, for k = 1, 2, ..., 12. Plot the test errors against k, one curve for each fixed value of m.\n",
    "\n",
    "What is a good choice of the pair (m,k), in terms of test error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bfdee-42f2-4874-ba37-52970a39be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_values = [50, 100, 150, 200]\n",
    "k_values = range(1, 13)\n",
    "\n",
    "errors = {}\n",
    "\n",
    "for m in m_values:\n",
    "    pca = PCA(n_components=m)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    for k in k_values:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        clf.fit(X_train_pca, y_train.ravel())\n",
    "        y_pred = clf.predict(X_test_pca)\n",
    "        errors[(m, k)] = 1 - accuracy_score(y_test, y_pred)\n",
    "        print('m =', m, 'k =', k, 'error =', errors[(m, k)])\n",
    "\n",
    "best_params = min(errors, key=errors.get)\n",
    "print('best_params =', best_params)\n",
    "print('error =', errors[best_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all lines for each m, k pair\n",
    "\n",
    "for m in m_values[1:]:\n",
    "    plt.plot(k_values, [errors[(m, k)] for k in k_values], label=f'm={m}')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('error')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75673134",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_m = best_params[0]\n",
    "best_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a8a33-ba2b-4601-b586-63ab122d1fbf",
   "metadata": {},
   "source": [
    "### 3 For the best value of m found above, perform unweighted kNN classification with city block distance ($\\ell_1$) for k = 1,2,..., 12. \n",
    "\n",
    "Plot the test errors against k. How does it compare with unweighted kNN + Euclidean metric ($\\ell_2$)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df3529-9d89-4472-8df5-123a316671a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(1, 13)\n",
    "\n",
    "manhatten_errors = []\n",
    "euclidean_errors = []\n",
    "\n",
    "pca = PCA(n_components=best_m)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "for k in k_values:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='manhattan')\n",
    "    clf.fit(X_train_pca, y_train.ravel())\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    manhatten_errors.append(1 - accuracy_score(y_test, y_pred))\n",
    "    print('Manhattan: m =', best_m, 'k =', k, 'error =', manhatten_errors[k-1])\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    clf.fit(X_train_pca, y_train.ravel())\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    euclidean_errors.append(1 - accuracy_score(y_test, y_pred))\n",
    "    print('Euclidean: m =', best_m, 'k =', k, 'error =', euclidean_errors[k-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, manhatten_errors, label='Manhatten')\n",
    "plt.plot(k_values, euclidean_errors, label='Euclidean')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('error')\n",
    "plt.grid()\n",
    "plt.title('Manhattan vs Euclidean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c66f8-af07-480e-8724-4640735ef8a8",
   "metadata": {},
   "source": [
    "### 4. For the best value of m found above, perform kNN classification + Euclidean metric, with inverse distance weights, for k = 1,2,...,12. \n",
    "\n",
    "Plot the test errors against k.  How does the weighted kNN compare with the unweighted kNN (both with Euclidean metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12333012-ab4e-4bb9-8c36-4a363186da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_errors = []\n",
    "\n",
    "for k in k_values:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean', weights='distance')\n",
    "    clf.fit(X_train_pca, y_train.ravel())\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    inverse_errors.append(1 - accuracy_score(y_test, y_pred))\n",
    "    print('Inverse: m =', best_m, 'k =', k, 'error =', inverse_errors[k-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, euclidean_errors, label='Euclidean Unweighted')\n",
    "plt.plot(k_values, inverse_errors, label='Euclidean Inverse')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('error')\n",
    "plt.grid()\n",
    "plt.title('Unweighted vs Inverse Euclidean Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d6889-2879-46f5-baad-6982dd01d4bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Implment the nearest local centroid classifier (with Euclidean distance) and apply it to the m-dimensional PCA reduced data for various values of k. \n",
    "\n",
    "Plot the test errors against k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02307bd-3640-4fb6-80cc-931caff9a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=0.2\n",
    "cmap_light = plt.cm.Paired\n",
    "cmap_bold = plt.cm.Paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(1, 13)\n",
    "\n",
    "errors = []\n",
    "\n",
    "pca = PCA(n_components=best_m)  # Reduce to 2 dimensions for visualization\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This algorithm is going to go through every training point and find the k nearest neighbors in each class of the training set\n",
    "# Then, for each class, it will calculate the centroid of the k nearest neighbors. For each centroid it will calculate the distance\n",
    "# to the test point. The predicted class is the one with the minimum distance.\n",
    "'''\n",
    "1. Isolate each class into a new variable\n",
    "2. Find the 5 closest points in that class to the test point\n",
    "3. Calculate the centroid of those 5 points\n",
    "4. Store the distance from the centroid to the test point\n",
    "5. Repeat for all classes\n",
    "6. The class with the minimum distance is the predicted class\n",
    "7. Store the predicted class\n",
    "8. Repeat for all test points\n",
    "9. Calculate the error\n",
    "'''\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3, metric='euclidean', weights='distance')\n",
    "clf.fit(X_train_pca, y_train.ravel())\n",
    "clf.classes_ = np.unique(y_train)  # Ensure all classes are included\n",
    "predicted_classes = []\n",
    "for point in X_test_pca:\n",
    "    distances = []\n",
    "    for i in clf.classes_:\n",
    "        X_class = X_train_pca[y_train.ravel() == i]\n",
    "        if len(X_class) > 0:\n",
    "            clf.fit(X_class, y_train[y_train.ravel() == i])\n",
    "            # find the closest points in that class to the test point\n",
    "            n_neighbors = min(5, len(X_class))\n",
    "            five_closest = clf.kneighbors(point.reshape(1, -1), n_neighbors=n_neighbors, return_distance=False)\n",
    "            centroid = np.mean(X_class[five_closest.flatten()], axis=0)\n",
    "\n",
    "            # store the distance from the centroid to the test point\n",
    "            distance = np.linalg.norm(centroid - point)\n",
    "            distances.append(distance)\n",
    "        else:\n",
    "            distances.append(np.inf)  # If there are no samples in the class, set distance to infinity\n",
    "    \n",
    "    # the class with the minimum distance is the predicted class\n",
    "    y_pred = clf.classes_[np.argmin(distances)]\n",
    "    predicted_classes.append(y_pred)\n",
    "\n",
    "errors.append(1 - accuracy_score(y_test, predicted_classes))\n",
    "print('error =', errors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean', weights='distance')\n",
    "    clf.fit(X_train_pca, y_train.ravel())\n",
    "    \n",
    "    # find the centroid of each class\n",
    "    centroids = np.zeros((len(clf.classes_), best_m))\n",
    "    for i in clf.classes_:\n",
    "        centroids[i] = np.mean(X_train_pca[y_train.ravel() == i], axis=0)\n",
    "\n",
    "    # For each test points, find the closest centroid\n",
    "    y_pred = np.zeros(y_test.shape)\n",
    "    for i in range(X_test_pca.shape[0]):\n",
    "        distances = np.linalg.norm(centroids - X_test_pca[i], axis=1)\n",
    "        y_pred[i] = np.argmin(distances)\n",
    "\n",
    "    error = 1 - accuracy_score(y_test, y_pred)\n",
    "    errors.append(error)\n",
    "    print(f'k = {k}, error = {error*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the training data in the PCA space\n",
    "scatter = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train.ravel(), cmap=cmap_bold, edgecolor='k', s=20)\n",
    "\n",
    "# Create a custom legend\n",
    "legend1 = plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.title('Training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f738c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, errors)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('error')\n",
    "plt.grid()\n",
    "plt.title('Nearest Local Centroid')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
